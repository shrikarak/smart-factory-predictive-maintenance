{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance for Smart Factory Equipment\n",
    "\n",
    "**Copyright (c) 2024 Shrikara Kaudambady. All rights reserved.**\n",
    "\n",
    "This notebook demonstrates how to build a predictive maintenance model using machine learning. The goal is to predict whether a piece of equipment will fail within a specific future time window, enabling proactive maintenance and reducing unplanned downtime in a smart factory setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Generation\n",
    "\n",
    "For this demonstration, we'll generate a synthetic dataset that mimics sensor readings from multiple machines over time. This data is inspired by the famous NASA Turbofan Engine Degradation dataset. \n",
    "\n",
    "Each machine operates for a variable number of cycles before it fails. The sensor readings will show a degradation trend as a machine approaches failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_machines=100, max_cycles=250, n_sensors=5):\n",
    "    data = []\n",
    "    np.random.seed(42)\n",
    "    for machine_id in range(1, n_machines + 1):\n",
    "        # Each machine has a random lifespan\n",
    "        lifespan = np.random.randint(120, max_cycles)\n",
    "        # Generate sensor data for the lifespan of the machine\n",
    "        for cycle in range(1, lifespan + 1):\n",
    "            row = {'machine_id': machine_id, 'cycle': cycle}\n",
    "            # Generate sensor readings\n",
    "            for sensor in range(1, n_sensors + 1):\n",
    "                # Add a degradation trend and noise\n",
    "                base_reading = np.random.normal(100, 10)\n",
    "                degradation = (cycle / lifespan) * np.random.uniform(10, 20) * (sensor * 0.5)\n",
    "                noise = np.random.normal(0, 2)\n",
    "                row[f'sensor_{sensor}'] = base_reading + degradation + noise\n",
    "            data.append(row)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = generate_synthetic_data()\n",
    "print(\"Synthetic dataset created. Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering and Labeling\n",
    "\n",
    "We need to calculate the Remaining Useful Life (RUL) for each machine. Then, we'll frame this as a classification problem: will the machine fail within the next `N` cycles? \n",
    "\n",
    "- `RUL`: For each row, RUL is the number of cycles remaining until that machine's final failure.\n",
    "- `label`: A binary label. `1` if RUL <= `N` (e.g., 30 cycles), `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RUL\n",
    "max_cycles = df.groupby('machine_id')['cycle'].max().reset_index()\n",
    "max_cycles.columns = ['machine_id', 'max_cycle']\n",
    "df = pd.merge(df, max_cycles, on='machine_id')\n",
    "df['RUL'] = df['max_cycle'] - df['cycle']\n",
    "\n",
    "# Create binary label\n",
    "warning_window = 30\n",
    "df['label'] = (df['RUL'] <= warning_window).astype(int)\n",
    "\n",
    "# Drop helper columns\n",
    "df = df.drop(columns=['max_cycle', 'RUL'])\n",
    "\n",
    "print(\"Labels created. Value counts:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's visualize the sensor data for a single machine to see the degradation trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_to_plot = df[df['machine_id'] == 1]\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(1, 6):\n",
    "    plt.plot(machine_to_plot['cycle'], machine_to_plot[f'sensor_{i}'], label=f'Sensor {i}')\n",
    "\n",
    "plt.title('Sensor Readings for Machine 1 Over Time')\n",
    "plt.xlabel('Cycle')\n",
    "plt.ylabel('Sensor Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Preparation for Modeling\n",
    "\n",
    "- Define features (`X`) and target (`y`).\n",
    "- Split data into training and testing sets.\n",
    "- Scale the features using `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df.columns if 'sensor' in col]\n",
    "X = df[features]\n",
    "y = df['label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test data shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training the Classification Model\n",
    "\n",
    "We'll use a Random Forest Classifier, which is a powerful and commonly used model for this type of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Random Forest model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluating Model Performance\n",
    "\n",
    "We will evaluate the model on the unseen test data using a confusion matrix and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Will Not Fail', 'Will Fail'], yticklabels=['Will Not Fail', 'Will Fail'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Feature Importance\n",
    "\n",
    "Let's see which sensor features were most important for the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances, y=feature_importances.index)\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Conclusion\n",
    "\n",
    "This notebook demonstrates a complete workflow for building a predictive maintenance model. The Random Forest classifier performed well, showing high precision and recall for the 'failure imminent' class (label 1).\n",
    "\n",
    "This model can be deployed in a smart factory to monitor equipment in real-time. By analyzing live sensor data, it can raise an alert when a machine is predicted to fail within the next 30 cycles, allowing the maintenance team to act proactively. This minimizes costly unplanned downtime and optimizes maintenance scheduling.\n",
    "\n",
    "**Copyright (c) 2024 Shrikara Kaudambady. All rights reserved.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
